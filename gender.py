# -*-) coding: utf-8 -*-
"""591warmup2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DT2ZHMD5EyPNo6zpBORuDkZpYhrzMD_3
"""


import torch
import torchvision
from torch.utils.data import Dataset
from torchvision.io import read_image
from torchvision.utils import save_image
from torchvision.transforms import ToTensor, Compose, Resize, Grayscale, Normalize, Lambda
import os
import torchvision.transforms as T
import matplotlib.pyplot as plt
import pandas as pd
from torch.utils.data import DataLoader
from torch import optim
import warnings
from torchvision.models import resnet18, ResNet18_Weights, resnet50
import torch.nn as nn
warnings.filterwarnings("ignore")
# Define a custom class for dataset
class CustomDataset(Dataset):
    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):
        self.img_labels = pd.read_csv(annotations_file, encoding='utf-8',encoding_errors='ignore')
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        image = read_image(img_path)
        image = T.ToPILImage() (image)
        label = self.img_labels.iloc[idx, 1]
        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
        return image, label

device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
print(device)

transform = Compose([
    ToTensor(),
    Lambda(lambda x: x.repeat(3,1,1)),
    Normalize((0.5,), (0.5,))
])
gender01_train_img_dir = './Gender01'
gender01_train_annotations_file = './Gender01/train.txt'

# Defining the training dataset and data loader
gender_train_dataset = CustomDataset(
    annotations_file=gender01_train_annotations_file,
    img_dir=gender01_train_img_dir,
    transform=transform,
)
gender_train_dataloader = DataLoader(gender_train_dataset, batch_size=64, shuffle=True)

gender01_test_img_dir = './Gender01'
gender01_test_annotations_file = './Gender01/test.txt'

# Defining the testing dataset and data loader
gender_test_dataset = CustomDataset(
    annotations_file=gender01_test_annotations_file,
    img_dir=gender01_test_img_dir,
    transform=transform
)
gender_test_loader = DataLoader(gender_test_dataset, batch_size=64, shuffle=True)

# Definining the resnet18 model

class Resnet18Classifier(nn.Module):
    def __init__(self, num_classes):
        super(Resnet18Classifier, self).__init__()
        self.resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)
        num_ftrs = self.resnet18.fc.in_features
        self.resnet18.fc = nn.Linear(num_ftrs, num_classes)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.resnet18(x)

num_classes = 2
model = Resnet18Classifier(num_classes).to(device)

loss_func = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = 0.001)
# resnet_18_classifier

# Defining the label mapping for each direction
label_mapping = {
    'male':0,
    'female':1
}

# Training the model
num_epochs = 20
for epoch in range(num_epochs):
    for images, labels in gender_train_dataloader:
        numeric_labels = [label_mapping[label] for label in labels]
        numeric_labels_tensor = torch.tensor(numeric_labels)
        images, labels = images.to(device), numeric_labels_tensor.to(device)
        optimizer.zero_grad()
        outputs = model(images)
#         print(f'Output is {outputs}')
#         print(f'Labels are {labels}')
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()
    # if epoch%20 == 0:
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

print("Training finished")

# Testing the model
correct = 0
total = 0
# Don't calculate gradients during evaluation
with torch.no_grad():
    for images, labels in gender_test_loader:
        numeric_labels = [label_mapping[label] for label in labels]
        numeric_labels_tensor = torch.tensor(numeric_labels)
        images, labels = images.to(device), numeric_labels_tensor.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        # print(f'Run for instance {total} and {correct}')

accuracy = 100 * correct / total
print(f"Test Accuracy for gender: {accuracy:.2f}%")







